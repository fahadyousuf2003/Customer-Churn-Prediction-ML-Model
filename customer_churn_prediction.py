# -*- coding: utf-8 -*-
"""Customer Churn Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10eeNdnActGcBhCRaFr0DrM2-rw9cBmU7
"""

# Including useful libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE

# Loading data into the dataset
customer_churn_dataset = pd.read_csv('/content/Churn_Modelling.csv')

# Checking first 5 rows of data
customer_churn_dataset.head()

# Checking last 5 rows of data
customer_churn_dataset.tail()

# Data Information
customer_churn_dataset.info()

# Checking the number of missing values in the data
customer_churn_dataset.isnull().sum()

# Identify categorical columns
categorical_columns = customer_churn_dataset.select_dtypes(include=['object']).columns.tolist()

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Apply label encoding to all categorical columns
for column in categorical_columns:
    customer_churn_dataset[column] = label_encoder.fit_transform(customer_churn_dataset[column])

# Split the data into features (X) and the target variable (Y)
X = customer_churn_dataset.drop(columns='Exited', axis=1)
Y = customer_churn_dataset['Exited']

# Handling Imbalanced Data with SMOTE

# Apply SMOTE to balance the dataset
smote = SMOTE(random_state=42)
X_resampled, Y_resampled = smote.fit_resample(X, Y)

# Split the resampled data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=42)

# Cross-validation with StratifiedKFold
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Initialize the RandomForestClassifier
classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit the classifier to the training data
classifier.fit(X_train, Y_train)

# Make predictions on the test set
Y_pred = classifier.predict(X_test)

# Evaluate the model on the test set
precision = precision_score(Y_test, Y_pred)
recall = recall_score(Y_test, Y_pred)
f1 = f1_score(Y_test, Y_pred)
roc_auc = roc_auc_score(Y_test, Y_pred)

# Print evaluation metrics
print("Test Set Precision: {:.2f}".format(precision))
print("Test Set Recall: {:.2f}".format(recall))
print("Test Set F1 Score: {:.2f}".format(f1))
print("Test Set ROC AUC: {:.2f}".format(roc_auc))

# Calculate accuracy
accuracy = accuracy_score(Y_test, Y_pred)

# Print the accuracy
print("Test Set Accuracy: {:.2f}%".format(accuracy * 100))